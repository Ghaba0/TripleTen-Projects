{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 15px; border: 3px solid indigo; padding: 15px;\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Hi, it's Sveta again. I was the reviewer on one of your previous projects, and I am going to review this one as well. I apologize for this egregious delay, and I hope it did not cause too much inconvenience. \n",
    "    \n",
    "    \n",
    "I will be using the same color marking:\n",
    "    \n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Great solutions and ideas that can and should be used in the future are in green comments.   \n",
    "</div>    \n",
    "    \n",
    "    \n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "\n",
    "Yellow color indicates what should be optimized. This is not necessary, but it will be great if you make changes to this project.\n",
    "</div>      \n",
    "    \n",
    "    \n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "\n",
    "Issues that need to be corrected to get right results are indicated in red comments. Note that the project cannot be accepted until these issues are resolved.\n",
    "</div>    \n",
    "\n",
    "<hr>\n",
    "    \n",
    "**Please, use some color other than those listed to highlight answers to my comments.**\n",
    "I would also ask you **not to change, move or delete my comments** so that it would be easier for me to navigate during the next review.\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "<hr>\n",
    "    \n",
    "<font color='dodgerblue'>**A few words about the project:**</font> this project is hard, but you did a pretty good job. There are several issues that need your attention. Please take a look. \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 15px; border: 3px solid indigo; padding: 15px;\">\n",
    "<b> Reviewer's comment 2</b>\n",
    "\n",
    "\n",
    "Thank you for the modifications. There's just a couple of questions. Would you take a look? \n",
    "    \n",
    "  \n",
    "</div>\n",
    "<hr>\n",
    "<div style=\"border-radius: 15px; border: 3px solid indigo; padding: 15px;\">\n",
    "<b> Reviewer's comment 3</b>\n",
    "\n",
    "\n",
    "Thank you for the correcctions! There's only one issue this time. Please take a look and reconsider the conclusions if needed.\n",
    "    \n",
    "  \n",
    "</div>\n",
    "<hr>\n",
    "<div style=\"border-radius: 15px; border: 3px solid indigo; padding: 15px;\">\n",
    "<b> Reviewer's comment 4</b>\n",
    "\n",
    "\n",
    "You did a great job, thank you so much! 😊 I do not have any questions, so our project has passed code review. Congratulations 😊\n",
    "    \n",
    "\n",
    "    \n",
    "Good luck! 😊   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "<hr>\n",
    "    \n",
    "    \n",
    "Best regards,\n",
    "    \n",
    "Sveta\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Customer Churn in Beta Bank: A Supervised Learning Approach\n",
    "\n",
    "\n",
    "This project aims to predict customer churn in Beta Bank by analyzing historical data on client behavior and contract terminations. Using supervised learning techniques, we seek to develop a model to identify customers likely to leave the bank soon. Our goal is to provide actionable insights to Beta Bank to optimize retention strategies and address customer attrition effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 'Tenure' column is the only one with missing values\n",
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "display(df)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a few columns because they're unnecessary\n",
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment</h2>\n",
    "    \n",
    "So, we can already notice that some of the data types can be changed. For instance, `HasCrCard` is probably a boolean type.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0     952\n",
      "2.0     950\n",
      "8.0     933\n",
      "3.0     928\n",
      "5.0     927\n",
      "7.0     925\n",
      "4.0     885\n",
      "9.0     882\n",
      "6.0     881\n",
      "10.0    446\n",
      "0.0     382\n",
      "Name: Tenure, dtype: int64\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking for any obvious missing values and duplicated rows\n",
    "print(df['Tenure'].value_counts())\n",
    "print()\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CreditScore           Age       Tenure        Balance  NumOfProducts  \\\n",
      "count  10000.000000  10000.000000  9091.000000   10000.000000   10000.000000   \n",
      "mean     650.528800     38.921800     4.997690   76485.889288       1.530200   \n",
      "std       96.653299     10.487806     2.894723   62397.405202       0.581654   \n",
      "min      350.000000     18.000000     0.000000       0.000000       1.000000   \n",
      "25%      584.000000     32.000000     2.000000       0.000000       1.000000   \n",
      "50%      652.000000     37.000000     5.000000   97198.540000       1.000000   \n",
      "75%      718.000000     44.000000     7.000000  127644.240000       2.000000   \n",
      "max      850.000000     92.000000    10.000000  250898.090000       4.000000   \n",
      "\n",
      "         HasCrCard  IsActiveMember  EstimatedSalary        Exited  \n",
      "count  10000.00000    10000.000000     10000.000000  10000.000000  \n",
      "mean       0.70550        0.515100    100090.239881      0.203700  \n",
      "std        0.45584        0.499797     57510.492818      0.402769  \n",
      "min        0.00000        0.000000        11.580000      0.000000  \n",
      "25%        0.00000        0.000000     51002.110000      0.000000  \n",
      "50%        1.00000        1.000000    100193.915000      0.000000  \n",
      "75%        1.00000        1.000000    149388.247500      0.000000  \n",
      "max        1.00000        1.000000    199992.480000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Are there any duplicates in `CustomerId` column? \n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>  Reviewer's comment </b>\n",
    "   \n",
    "\n",
    "- It may be useful to print some statistics to evaluate the dataset. Simple `describe` method would suffice. \n",
    "\n",
    "\n",
    "- We can also convert column names from camel to snake case. \n",
    "\n",
    "\n",
    "- Unnecessary columns can be removed.\n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2 </h2>\n",
    "    \n",
    "Looks better! \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in the missing values in the 'Tenure' column with the mean because there aren't any outliers or anything \n",
    "df['Tenure'].fillna(df['Tenure'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment</h2>\n",
    "    \n",
    "Yes, we should fill in these gaps. \n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "However, you said we could use the average because \"there aren't any outliers or anything\". How do you know that? Isn't it safer to just use the median? \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ I know this because I looked at the value_counts of the column and all the values were mostly equal except for the maximum and the minimum values which I think makes sense. Also, with the .describe stats, we can see that the mean basically is the median so it won't make much of a difference anyway. But I will change it to median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2 </h2>\n",
    "    \n",
    "Makes sense. Thank you for the clarification. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: Geography, dtype: int64\n",
      "\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "0.00         3617\n",
      "105473.74       2\n",
      "130170.82       2\n",
      "72594.00        1\n",
      "139723.90       1\n",
      "             ... \n",
      "130306.49       1\n",
      "92895.56        1\n",
      "132005.77       1\n",
      "166287.85       1\n",
      "104001.38       1\n",
      "Name: Balance, Length: 6382, dtype: int64\n",
      "\n",
      "1    5084\n",
      "2    4590\n",
      "3     266\n",
      "4      60\n",
      "Name: NumOfProducts, dtype: int64\n",
      "\n",
      "37    478\n",
      "38    477\n",
      "35    474\n",
      "36    456\n",
      "34    447\n",
      "     ... \n",
      "92      2\n",
      "88      1\n",
      "82      1\n",
      "85      1\n",
      "83      1\n",
      "Name: Age, Length: 70, dtype: int64\n",
      "\n",
      "9565    1\n",
      "5878    1\n",
      "3265    0\n",
      "4111    1\n",
      "1474    1\n",
      "Name: IsActiveMember, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Can use label encoding to replace the Geography and Gender columns since there's only 2-3 different values in each\n",
    "# Nothing looks out of place to me\n",
    "print(df['Geography'].value_counts())\n",
    "print()\n",
    "print(df['Gender'].value_counts())\n",
    "print()\n",
    "print(df['Balance'].value_counts())\n",
    "print()\n",
    "print(df['NumOfProducts'].value_counts())\n",
    "print()\n",
    "print(df['Age'].value_counts())\n",
    "print()\n",
    "print(df['IsActiveMember'].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Let's analyze other columns to make sure the data looks normal. \n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 2</b>\n",
    "    \n",
    "There are more than 3 columns :)     \n",
    "</div>\n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>  Reviewer's comment 3 </h2>\n",
    "   \n",
    "\n",
    "When you have a lot of values, use charts instead of `value_counts()`, since the latter will not give you enough information. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42     2.0       0.00              1          1   \n",
       "1             608   41     1.0   83807.86              1          0   \n",
       "2             502   42     8.0  159660.80              3          1   \n",
       "3             699   39     1.0       0.00              2          0   \n",
       "4             850   43     2.0  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39     5.0       0.00              2          1   \n",
       "9996          516   35    10.0   57369.61              1          1   \n",
       "9997          709   36     7.0       0.00              1          0   \n",
       "9998          772   42     3.0   75075.31              2          1   \n",
       "9999          792   28     5.0  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OHE for Geography and Gender\n",
    "\n",
    "df_ohe = pd.get_dummies(df, columns=['Geography', 'Gender'], drop_first=True) # Fixed\n",
    "\n",
    "display(df_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 3</b>\n",
    "    \n",
    "Please don't forget about `drop_first` parameter.     \n",
    "</div>\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>   Reviewer's comment 4 ✔️</h2>\n",
    "    \n",
    "Good. Using `drop_first=True` may help you avoid multicollinearity.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2 </h2>\n",
    "    \n",
    "> I used label encoding because I was told that OHE should generally only be used for regression models\n",
    "    \n",
    "    \n",
    "Like many other methods, OHE methods have pros and cons, but it does not mean we should use them for regression only. OHE works fine with classification, but it increases the dimension.\n",
    "    \n",
    "    \n",
    "> But when I tried to train the model, it gave me an error: 'ValueError: could not convert string to float'\n",
    "    \n",
    "I do not see the code, so I cannot suggest anything here. \n",
    "   \n",
    "    \n",
    "    \n",
    "> I thought that I might just remove the surname column, but I think it could have some importance in the data?\n",
    "    \n",
    "    \n",
    "If a feature does not influence people's decisions regarding leaving the bank, then we do not need to include these columns in the analysis. Row numbers, ids, and last names should not have such influence, so it is save to drop them. It will reduce the size of the dataframe and make the calculations faster.  \n",
    "    \n",
    "    \n",
    "    \n",
    "</div><div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 2</b>\n",
    "    \n",
    " \n",
    "    \n",
    "> If you still think I should change it to OHE, that's no problem, I'm just explaining why I did it this way\n",
    "    \n",
    "    \n",
    "It is not a probelm that you use ordinal encoding. The problem is in the way you are using it. We must encode categorical data only. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "- Only categorical features should be encoded.\n",
    "   \n",
    "\n",
    "- Please specify why you decided to choose ordinal encoding. The OHE methods seem more preferable here. For instance, one-hot encoding helps us ensure the model does not misinterpret categorical features as having some ordinal relationships.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>  Reviewer's comment </h2>\n",
    "   \n",
    "\n",
    "[PEP8](https://peps.python.org/pep-0008/) states that one should always put import at the top of the file. It's a good practice, since everyone who is going to read the project, can immediately figure out what modules need to be installed. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ I usually would haha but I've been told before that there's no reason to put them all at the top and got flagged for it, so I've been spreading them out. I'll change that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2</h2>\n",
    "    \n",
    "I gave you a reason in the comment above :) \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize temp train df and test df\n",
    "# I split 20% because it is a large dataset and I'm splitting it twice which would only leave 50% for training if I used 25%\n",
    "\n",
    "df_train_temp, df_test = train_test_split(\n",
    "    df_ohe, \n",
    "    test_size=.2, # Split 20% of data to make test set\n",
    "    random_state=12345)\n",
    "\n",
    "# initialize valid df and actual train df\n",
    "df_train, df_valid = train_test_split(\n",
    "    df_train_temp, \n",
    "    test_size=0.2,  # Split another 20% of data to make validation set\n",
    "    random_state=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>  Reviewer's comment </h2>\n",
    "   \n",
    "\n",
    "There's a `stratify` parameter that help us ensure the random split saves the initial proportion of values in some column.   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "features = df_ohe.drop(['Exited'], axis=1)\n",
    "target = df_ohe['Exited']\n",
    "\n",
    "features_train = df_train.drop(['Exited'], axis=1)\n",
    "target_train = df_train['Exited']\n",
    "\n",
    "features_test = df_test.drop(['Exited'], axis=1)\n",
    "target_test = df_test['Exited']\n",
    "\n",
    "features_valid = df_valid.drop(['Exited'], axis=1)\n",
    "target_valid = df_valid['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment </h2>\n",
    "    \n",
    "Correct.\n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>  Reviewer's comment </h2>\n",
    "   \n",
    "\n",
    "After you successfully split the data, you can scale it, it never hurts.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without class weight:\n",
      "\n",
      "Recall: 0.44983818770226536\n",
      "\n",
      "Precision: 0.7679558011049724\n",
      "\n",
      "F1 score: 0.5673469387755101\n",
      "\n",
      "Valid acc: 0.8675\n",
      "\n",
      "AUC-ROC value: 0.7086526337426897\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree model and train it without class_weight\n",
    "\n",
    "'''\n",
    "best_f1 = 0\n",
    "best_accuracy = 0\n",
    "best_est = 0\n",
    "for est in range(1, 21):\n",
    "    tree1 = DecisionTreeClassifier(random_state=12345, max_depth=est)\n",
    "    tree1.fit(features_train, target_train)\n",
    "    # Predict on validation set to calculate F1 score\n",
    "    tree1_predicted_valid = tree1.predict(features_valid)\n",
    "    # Calculate accuracy score on validation set\n",
    "    accuracy = accuracy_score(target_valid, tree1_predicted_valid)\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(target_valid, tree1_predicted_valid)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_est = est\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (max_depth = {}): {}\".format(best_est, best_accuracy)) # Best for both\n",
    "print(\"Best f1 score of the best model on the validation set (max_depth = {}): {}\".format(best_est, best_f1)) # is max_depth=6\n",
    "'''\n",
    "tree1 = DecisionTreeClassifier(random_state=12345, max_depth=6)\n",
    "tree1.fit(features_train, target_train)\n",
    "\n",
    "tree1_predicted_valid = tree1.predict(features_valid)\n",
    "\n",
    "print()\n",
    "print('Without class weight:')\n",
    "print()\n",
    "print('Recall:', recall_score(target_valid, tree1_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, tree1_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, tree1_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, tree1_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, tree1_predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With class weight:\n",
      "\n",
      "Recall: 0.5307443365695793\n",
      "\n",
      "Precision: 0.49101796407185627\n",
      "\n",
      "F1 score: 0.5101088646967341\n",
      "\n",
      "Valid acc: 0.803125\n",
      "\n",
      "AUC-ROC value: 0.69953173451252\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree model and train it with class_weight\n",
    "\n",
    "'''\n",
    "best_f1 = 0\n",
    "best_accuracy = 0\n",
    "best_est = 0\n",
    "for est in range(1, 21):\n",
    "    tree2 = DecisionTreeClassifier(random_state=12345, max_depth=est, class_weight='balanced')\n",
    "    tree2.fit(features_train, target_train)\n",
    "    # Predict on validation set to calculate F1 score\n",
    "    tree2_predicted_valid = tree2.predict(features_valid)\n",
    "    # Calculate accuracy score on validation set\n",
    "    accuracy = accuracy_score(target_valid, tree2_predicted_valid)\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(target_valid, tree2_predicted_valid)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_est = est\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (max_depth = {}): {}\".format(best_est, best_accuracy)) # Best for both\n",
    "print(\"Best f1 score of the best model on the validation set (max_depth = {}): {}\".format(best_est, best_f1)) # is max_depth=16\n",
    "'''\n",
    "tree2 = DecisionTreeClassifier(random_state=12345, max_depth=16, class_weight='balanced')\n",
    "tree2.fit(features_train, target_train)\n",
    "\n",
    "tree2_predicted_valid = tree2.predict(features_valid)\n",
    "\n",
    "print()\n",
    "print('With class weight:')\n",
    "print()\n",
    "print('Recall:', recall_score(target_valid, tree2_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, tree2_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, tree2_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, tree2_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, tree2_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 2 </b>\n",
    "    \n",
    "Please add the code if you write about its results in the conclusions.\n",
    "</div>\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 3 </h2>\n",
    "    \n",
    "Good! The results may change though. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unbalanced DecisionTreeClassifier class_weight Conclusion**\n",
    "\n",
    "A balanced class_weight in the DecisionTree model lowered the accuracy by ~.06, raised the recall by ~.11, lowered f1 score by ~.05, lowered precision by ~.27, and left the AUC-ROC basically the same so I think the one without class_weight is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "What can be concluded from the output above? \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ I moved the balance check to after the conclusion for the three models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "Here and further, let's add AUC-ROC score. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without class_weight:\n",
      "\n",
      "Recall: 0.47896440129449835\n",
      "\n",
      "Precision: 0.7956989247311828\n",
      "\n",
      "F1 score: 0.5979797979797981\n",
      "\n",
      "Valid acc: 0.875625\n",
      "\n",
      "AUC-ROC value: 0.7247649272158008\n"
     ]
    }
   ],
   "source": [
    "# Try a RandomForestClassifier without balance\n",
    "\n",
    "'''\n",
    "# Test to find optimal n_estimators value\n",
    "best_f1 = 0\n",
    "best_accuracy = 0\n",
    "best_est = 0\n",
    "for est in range(1, 101): #\n",
    "    forest1 = RandomForestClassifier(random_state=54321, n_estimators=est) # set number of n_estimators\n",
    "    forest1.fit(features_train, target_train) # train model on training set\n",
    "    forest1_predicted_valid = forest1.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, forest1_predicted_valid) # calculate accuracy score on validation set\n",
    "    f1 = f1_score(target_valid, forest1_predicted_valid)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_est = est\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_accuracy)) # 96\n",
    "print(\"Best f1 score of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_f1)) # 96\n",
    "'''\n",
    "\n",
    "forest1 = RandomForestClassifier(random_state=54321, n_estimators=96)\n",
    "forest1.fit(features_train, target_train)\n",
    "\n",
    "forest1_predicted_valid = forest1.predict(features_valid)\n",
    "\n",
    "print('Without class_weight:')\n",
    "print()\n",
    "print('Recall:', recall_score(target_valid, forest1_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, forest1_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, forest1_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, forest1_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, forest1_predicted_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With class_weight:\n",
      "\n",
      "Recall: 0.4627831715210356\n",
      "\n",
      "Precision: 0.7606382978723404\n",
      "\n",
      "F1 score: 0.5754527162977867\n",
      "\n",
      "Valid acc: 0.868125\n",
      "\n",
      "AUC-ROC value: 0.7139632356443287\n"
     ]
    }
   ],
   "source": [
    "# Try a RandomForestClassifier with balance\n",
    "\n",
    "'''\n",
    "# Test to find optimal n_estimators value\n",
    "best_f1 = 0\n",
    "best_accuracy = 0\n",
    "best_est = 0\n",
    "for est in range(1, 101): #\n",
    "    forest2 = RandomForestClassifier(random_state=54321, n_estimators=est, class_weight='balanced') # set number of n_estimators\n",
    "    forest2.fit(features_train, target_train) # train model on training set\n",
    "    forest2_predicted_valid = forest2.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, forest2_predicted_valid) # calculate accuracy score on validation set\n",
    "    f1 = f1_score(target_valid, forest2_predicted_valid)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_est = est\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_accuracy)) # 39\n",
    "print(\"Best f1 score of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_f1)) # 39\n",
    "'''\n",
    "\n",
    "forest2 = RandomForestClassifier(random_state=54321, n_estimators=39, class_weight='balanced')\n",
    "forest2.fit(features_train, target_train)\n",
    "\n",
    "forest2_predicted_valid = forest2.predict(features_valid)\n",
    "\n",
    "print('With class_weight:')\n",
    "print()\n",
    "print('Recall:', recall_score(target_valid, forest2_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, forest2_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, forest2_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, forest2_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, forest2_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unbalanced RandomForestClassifier class_weight Conclusion**\n",
    "\n",
    "A balanced class weight reduced recall by ~.01, lowered precision by ~.03, lowered f1 score by ~.02, lowered accuracy by ~.01, and lowered AOC-ROC by ~.01 so I think the model without a balanced class weight performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 2</b>\n",
    "    \n",
    "\n",
    "Add the code without class_weight here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without class_weight:\n",
      "\n",
      "Recall: 0.009708737864077669\n",
      "\n",
      "Precision: 0.6\n",
      "\n",
      "F1 score: 0.01910828025477707\n",
      "\n",
      "Valid acc: 0.8075\n",
      "\n",
      "AUC-ROC value: 0.5040797755935416\n"
     ]
    }
   ],
   "source": [
    "# Trying out a logistic regression model without class_weight variable\n",
    "\n",
    "logReg1 = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "logReg1.fit(features_train, target_train)\n",
    "\n",
    "log1_predicted_valid = logReg1.predict(features_valid)\n",
    "\n",
    "print('Without class_weight:')\n",
    "print()\n",
    "print('Recall:', recall_score(target_valid, log1_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, log1_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, log1_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, log1_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, log1_predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With class_weight:\n",
      "\n",
      "Recall: 0.6731391585760518\n",
      "\n",
      "Precision: 0.33015873015873015\n",
      "\n",
      "F1 score: 0.44302449414270506\n",
      "\n",
      "Valid acc: 0.673125\n",
      "\n",
      "AUC-ROC value: 0.6731303848650979\n"
     ]
    }
   ],
   "source": [
    "# Trying out a logistic regression model with class_weight variable\n",
    "\n",
    "logReg2 = LogisticRegression(solver='liblinear', random_state=12345, class_weight='balanced')\n",
    "logReg2.fit(features_train, target_train)\n",
    "\n",
    "log2_predicted_valid = logReg2.predict(features_valid)\n",
    "\n",
    "print('With class_weight:')\n",
    "print()\n",
    "print('Recall:', recall_score(target_valid, log2_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, log2_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, log2_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, log2_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, log2_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unbalanced LogisticRegression class_weight Conclusion**\n",
    "\n",
    "Balancing the class weight for the LogisticRegression model improved the recall by ~.66, reduced the precision by ~.27, improved the f1 score by ~.42, reduced the accuracy by ~.13, and increased the AOC-ROC by ~.17. I think class_weight does help this model but it doesn't really matter because it's still really bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think in general, class_weight='balanced' made the models worse, but not by that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "Code is missing here as well. We have to show the result, not just tell about it. \n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 3 </h2>\n",
    "    \n",
    "Indeed, it looks like it did not help. However, we still need to check everything again, since the results may change. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stats Comparisons Without Class_Weight='balanced'\n",
    "\n",
    "**Recall:**\n",
    "* Worst - LogisticRegression\n",
    "* Best - RandomForestClassifier\n",
    "\n",
    "**Precision:**\n",
    "* Worst - LogisticRegression\n",
    "* Best - RandomForestClassifier\n",
    "\n",
    "**F1 Score:**\n",
    "* Worst - LogisticRegression\n",
    "* Best - RandomForestClassifier\n",
    "\n",
    "**Valid Accuracy:**\n",
    "* Worst - LogisticRegression\n",
    "* Best - RandomForestClassifier\n",
    "\n",
    "**AUC-ROC Value:**\n",
    "* Worst - LogisticRegression\n",
    "* Best - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty clear that LogisticRegression is the worst and RandomForest is the best, at least before balancing the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "- Please add the code you used here. \n",
    "    \n",
    "\n",
    "- Try other models as well.\n",
    "\n",
    "\n",
    "- Compare the results. \n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 2</b>\n",
    "    \n",
    "\n",
    "Yes, we should provide the code. Conclusions are not reliable without the results, right? \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>  Reviewer's comment </b>\n",
    "   \n",
    "\n",
    "It may be a bit confusing that a conclusion is defined with the level-1 heading :) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Before we move on to the resampling, let's check whether a simple `class_weight` parameter can help here. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n",
      "0    5099\n",
      "1    1301\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of classes\n",
    "\n",
    "print(df_ohe['Exited'].value_counts())\n",
    "print(df_train['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an imbalance in the classes. 1.0 has about 1/4 the amount of 0.0.\n",
    "\n",
    "In 'real' terms, it means that about a quarter of the customers have already left the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2602\n",
      "0    2549\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Downsample + Upsample\n",
    "# My plan is to upsample by 2 and downsample by 2 since that would make the two classes a very close number. ~4000\n",
    "# I wanted to do this so that I create and delete an equal number so it's even more? balanced?\n",
    "# It just sounded like a good idea\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_train[df_train['Exited'] == 0]\n",
    "df_minority = df_train[df_train['Exited'] == 1]\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = df_majority.sample(n=len(df_majority)//2, random_state=123)\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = df_minority.sample(n=len(df_minority)*2, replace=True, random_state=123)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_resampled = pd.concat([df_majority_downsampled, df_minority_upsampled])\n",
    "\n",
    "# Shuffle the dataset to randomize the order of samples\n",
    "df_resampled = df_resampled.sample(frac=1, random_state=123)\n",
    "\n",
    "# Display class counts to verify balance\n",
    "print(df_resampled['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment</h2>\n",
    "    \n",
    "Nice code! It's great that you use `sample` and define `random state`. \n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>  Reviewer's comment </h2>\n",
    "   \n",
    "\n",
    "It would be perfect if you defined it as a method that can be called. \n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Resampling should be applied to train data only. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ That does make more sense, now I don't have to split the data up again too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2</h2>\n",
    "    \n",
    "Exacltly. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new training variables\n",
    "features_train = df_resampled.drop(['Exited'], axis=1)\n",
    "target_train = df_resampled['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6472491909385113\n",
      "\n",
      "Precision: 0.4424778761061947\n",
      "\n",
      "F1 score: 0.5256241787122208\n",
      "\n",
      "Valid acc: 0.774375\n",
      "\n",
      "AUC-ROC value: 0.7260258348185972\n"
     ]
    }
   ],
   "source": [
    "# Fit new tree model to new resampled data\n",
    "\n",
    "'''\n",
    "best_f1 = 0\n",
    "best_accuracy = 0\n",
    "best_est = 0\n",
    "for est in range(1, 21):\n",
    "    tree = DecisionTreeClassifier(random_state=12345, max_depth=est)\n",
    "    tree.fit(features_train, target_train)\n",
    "    # Predict on validation set to calculate F1 score\n",
    "    tree_predicted_valid = tree.predict(features_valid)\n",
    "    # Calculate accuracy score on validation set\n",
    "    accuracy = accuracy_score(target_valid, tree_predicted_valid)\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(target_valid, tree_predicted_valid)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_est = est\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (max_depth = {}): {}\".format(best_est, best_accuracy)) # 18\n",
    "print(\"Best f1 score of the best model on the validation set (max_depth = {}): {}\".format(best_est, best_f1)) # 18\n",
    "'''\n",
    "tree = DecisionTreeClassifier(random_state=12345, max_depth=18)\n",
    "tree.fit(features_train, target_train)\n",
    "\n",
    "tree_predicted_valid = tree.predict(features_valid)\n",
    "\n",
    "print('Recall:', recall_score(target_valid, tree_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, tree_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, tree_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, tree_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, tree_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2</h2>\n",
    "    \n",
    "Although it may be useful in some cases, using ``class_weight` here is not necessary. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings with balanced data (DecisionTree)\n",
    "\n",
    "Training the tree model on the sampled data increased recall by ~.19, reduced precision by ~.31, reduced the f1 score by ~.04, lowered the accuracy by ~.08, and increased the AOC-ROC value by ~.2.\n",
    "\n",
    "Overall a reduction in quality because the f1 score was reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Please make the conclusions broader so that a reader does not need to scroll up and read the previous one in order to compare the models. \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2 </h2>\n",
    "    \n",
    "Great!     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without class_weight:\n",
      "\n",
      "Recall: 0.6699029126213593\n",
      "\n",
      "Precision: 0.5734072022160664\n",
      "\n",
      "F1 score: 0.617910447761194\n",
      "\n",
      "Valid acc: 0.84\n",
      "\n",
      "AUC-ROC value: 0.7753077692463884\n"
     ]
    }
   ],
   "source": [
    "# Trying RandomForestClassifier\n",
    "\n",
    "'''\n",
    "# Test to find optimal n_estimators value\n",
    "best_f1 = 0\n",
    "best_accuracy = 0\n",
    "best_est = 0\n",
    "for est in range(1, 101): #\n",
    "    forest = RandomForestClassifier(random_state=54321, n_estimators=est) # set number of n_estimators\n",
    "    forest.fit(features_train, target_train) # train model on training set\n",
    "    forest_predicted_valid = forest.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, forest_predicted_valid) # calculate accuracy score on validation set\n",
    "    f1 = f1_score(target_valid, forest_predicted_valid)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_est = est\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_accuracy)) # 39\n",
    "print(\"Best f1 score of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_f1)) # 39\n",
    "'''\n",
    "\n",
    "forest = RandomForestClassifier(random_state=54321, n_estimators=39)\n",
    "forest.fit(features_train, target_train)\n",
    "\n",
    "forest_predicted_valid = forest.predict(features_valid)\n",
    "\n",
    "print('Without class_weight:')\n",
    "print()\n",
    "print('Recall:', recall_score(target_valid, forest_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, forest_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, forest_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, forest_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, forest_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings with balanced data (RandomForest)\n",
    "\n",
    "Training the forest model on the new resampled data increased recall by almost .2, reduced precision by ~.22, increased the f1 score by ~.03, reduced the accuracy by ~.03, and increased the AOC-ROC value by ~.05.\n",
    "\n",
    "Overall a increase in quality because the F1 score increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>   Reviewer's comment 4 ✔️</h2>\n",
    "    \n",
    "Very good.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "Please add AUC-ROC score. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6796116504854369\n",
      "\n",
      "Precision: 0.3115727002967359\n",
      "\n",
      "F1 score: 0.427263479145473\n",
      "\n",
      "Valid acc: 0.648125\n",
      "\n",
      "AUC-ROC value: 0.6601001707113475\n"
     ]
    }
   ],
   "source": [
    "# Trying Logistic Regression\n",
    "\n",
    "logReg = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "logReg.fit(features_train, target_train)\n",
    "\n",
    "logReg_predicted_valid = logReg.predict(features_valid)\n",
    "\n",
    "print('Recall:', recall_score(target_valid, logReg_predicted_valid))\n",
    "print()\n",
    "print('Precision:', precision_score(target_valid, logReg_predicted_valid))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_valid, logReg_predicted_valid))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_valid, logReg_predicted_valid))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_valid, logReg_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings with balanced data (LogisticReg)\n",
    "\n",
    "Training the LogisticRegression model on the resampled data greatly increased the recall by about .66, reduced the precision by ~.36, increased the F1 score by ~.4, reduced the accuracy by ~.16, and increased the AOC-ROC value by ~.15.\n",
    "\n",
    "Definitely a better model than it was before, but still not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "Please don't forget to add AUC-ROC score and try this model in the previous section, with the unbalanced data. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier performed the best**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 2</h2>\n",
    "    \n",
    "Yes, it indeed performs better. Now we can evaluate F1 score on test data. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6276346604215457\n",
      "\n",
      "Precision: 0.5763440860215053\n",
      "\n",
      "F1 score: 0.600896860986547\n",
      "\n",
      "Valid acc: 0.822\n",
      "\n",
      "AUC-ROC value: 0.7511981312279374\n"
     ]
    }
   ],
   "source": [
    "# Perform final test with Random Forest Classifier on test df\n",
    "\n",
    "forest_predicted_test = forest.predict(features_test)\n",
    "\n",
    "print('Recall:', recall_score(target_test, forest_predicted_test))\n",
    "print()\n",
    "print('Precision:', precision_score(target_test, forest_predicted_test))\n",
    "print()\n",
    "print('F1 score:', f1_score(target_test, forest_predicted_test))\n",
    "print()\n",
    "print('Valid acc:', accuracy_score(target_test, forest_predicted_test))\n",
    "print()\n",
    "print('AUC-ROC value:', roc_auc_score(target_test, forest_predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>  Reviewer's comment 4 </h2>\n",
    "   \n",
    "\n",
    "By the way, on final tests of your model, you can train it on full data (train + valid) and then check the score on test data.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "- Prepared the data for training\n",
    "- Provided explanation of preprocessing steps\n",
    "- Investigated the balance of classes within the dataset\n",
    "- Studied the model without considering class imbalance\n",
    "- Split the data into training, validation, and testing sets\n",
    "- Implemented techniques to address class imbalance\n",
    "- Ensured proper model training, validation, and final testing procedures were followed\n",
    "- Achieved a high F1 score\n",
    "- Examined AUC-ROC values to assess model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion on Class Weights\n",
    "\n",
    "After experimenting with class weights in the models, it became evident that their impact varied across different classifiers. Notably, the use of balanced class weights generally resulted in either minor improvements or slight deteriorations in model performance. \n",
    "\n",
    "### DecisionTreeClassifier with class_weight\n",
    "\n",
    "Introducing a balanced class weight to the DecisionTree model led to a decrease in accuracy by approximately 0.06, while increasing recall by around 0.1. However, this adjustment also resulted in a reduction in the F1 score by approximately 0.04 and a significant decrease in precision by about 0.26. Considering the negligible change in the AUC-ROC, it's concluded that the model without class_weight performs better.\n",
    "\n",
    "### RandomForestClassifier with class_weight\n",
    "\n",
    "Applying a balanced class weight to the RandomForest model maintained the recall at the same level as the unbalanced model. However, it significantly decreased precision by approximately 0.5, leading to a minor reduction in the F1 score by around 0.01 and a notable decrease in accuracy by approximately 0.1. Additionally, the AUC-ROC decreased slightly by about 0.004. Thus, it's determined that the model without a balanced class weight performs better.\n",
    "\n",
    "### LogisticRegression with class_weight\n",
    "\n",
    "Balancing the class weight for the LogisticRegression model notably improved recall by approximately 0.7, although it also led to a substantial reduction in precision by around 0.31. This improvement resulted in a significant increase in the F1 score by approximately 0.45. However, there was a considerable decrease in accuracy by about 0.11, alongside an increase in the AUC-ROC by approximately 0.19. Despite these improvements, the overall performance remains unsatisfactory.\n",
    "\n",
    "In conclusion, while the impact of class_weight='balanced' varied across models, it generally did not significantly enhance performance. Moreover, it's evident that LogisticRegression consistently underperforms compared to DecisionTree and RandomForest models, especially before balancing the classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "After resampling the data, significant effects were observed on the models. The RandomForest model demonstrated the most notable improvement, particularly in its F1 score, which experienced a substantial increase due to achieving similar recall and precision values (approximately 0.62). Conversely, the DecisionTree model showcased a peculiar response to the resampled data, as it encountered a considerable decrease in precision despite maintaining relatively unchanged performance in other metrics.\n",
    "\n",
    "Among the selected models, LogisticRegression displayed the poorest performance. Despite minimal changes observed with the balanced data, it exhibited a slight deterioration in all aspects, further emphasizing its inadequate performance even before the introduction of new data.\n",
    "\n",
    "When examining each model's performance with balanced data individually:\n",
    "\n",
    "- The DecisionTree model saw a notable increase in recall (~0.19) but suffered a significant decrease in precision (~0.31), resulting in a slight reduction in the F1 score (~0.04).\n",
    "- The RandomForest model experienced a substantial increase in recall (~0.2) and a slight improvement in the F1 score (~0.03), despite a decrease in precision (~0.22).\n",
    "- The LogisticRegression model exhibited a remarkable boost in recall (~0.66) but also a significant reduction in precision (~0.36), resulting in a substantial increase in the F1 score (~0.4).\n",
    "\n",
    "While each model responded differently to the resampled data, it is evident that careful consideration is necessary when interpreting their performances in the context of class imbalance and data preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "Please elaborate on it. What can we infer? In the text above, you provided the results (what has been done), but can we conclude from these results? Did the resampling help? Which model shows the best performance? What can be improved in these models? \n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 2</b>\n",
    "    \n",
    "\n",
    "Looks very good! Please don't forget to update the conclusions after the updates. \n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment 3</b>\n",
    "    \n",
    "\n",
    "Let's keep this comment relevant because updates in the OHE method may cause some changes.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment 4</h2>\n",
    "    \n",
    "Great job, thank you so much!     \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
